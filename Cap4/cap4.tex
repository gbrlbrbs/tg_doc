In this chapter, we will describe the problem's modelling and the main tools being used.

\section{Environment} \label{sec:env}

The environment used for this work is a computer with an Intel i5-8300H CPU, 16GB of RAM and an NVIDIA GeForce GTX 1050 GPU with 4GB of VRAM. The operating system is Arch Linux.

\section{Data}

In this work, we will be using data for COVID hospitalizations in the city of São José dos Campos. The data is structured as tabular data with most columns encoded as binary values. The columns are:

\begin{enumerate}
    \item \texttt{Fever}: If the patient had fever or not;
    \item \texttt{Cough}: If the patient had cough or not;
    \item \texttt{Sore throat}: If the patient had sore throat or not;
    \item \texttt{Dyspnea}: If the patient had dyspnea or not;
    \item \texttt{Respiratory.distress}: If the patient had respiratory discomfort or not;
    \item \texttt{Oxygen.saturation}: If the patient had low oxygen saturation or not;
    \item \texttt{Diarrhea}: If the patient had diarrhea or not;
    \item \texttt{Vomit}: If the patient was vomiting or not;
    \item \texttt{Other.symptoms}: If the patient had other symptoms or not;
    \item \texttt{Chronic.cardiovascular.disease}: If the patient had chronic cardiovascular disease or not;
    \item \texttt{Immunodeficiency.immunodepression}: If the patient had immunodeficiency/immunodepression or not;
    \item \texttt{Diabetes.mellitus}: If the patient had diabetes mellitus or not;
    \item \texttt{Obesity}: If the patient was obese or not;
    \item \texttt{Chronic.respiratory.disease}: If the patient had chronic respiratory disease or not;
    \item \texttt{Other.risks}: If the patient had other risks not related to the ones before or not;
    \item \texttt{Sex}: Whether male or female;
    \item \texttt{Age}: The patient's age;
    \item \texttt{Hospitalization}: If the patient was hospitalized or not;
\end{enumerate}

From this data we already have an instance space, with corresponding meta-features and projection matrix.

\section{Decoder-Encoder creation, loss function and training}

The implementation of the decoder-encoder model is straightforward. Using the PyTorch \cite{paszke2019pytorch} framework we can define classes that function as neural network models. It has methods for backpropagation and has multiple optimizers implemented. 

The decoder model will decode the normalized instance space values into the normalized meta-features, while the encoder will encode the normalized meta-features into the normalized instance space values. The decoder will have the same number of layers as the encoder, but with the number of output features in each layer being the reverse of the encoder. The activation function for each layer, except the final layer, will be the ReLU function \cite{agarap2019deep}.

We will be using the Adam optimizer \cite{kingma2017adam} for training. The loss function will be the mean squared error, since all the meta-features are continuous. The training of the model will be done in batches of 250 observations. We will also log the epoch losses in TensorBoard.

\section{Data generation}

For data generation, we will define a region of the IS where we will sample points. Those points will then be normalized under the mean and standard deviation of the original IS and passed into the trained decoder to go from the instance space into the meta-features space.

\section{Instance Space generation}

For the IS generation, we will use the projection matrix and meta-features from the original IS. The meta-features generated will be multiplied by the projection matrix to generate the IS coordinates for each observation. We will then use the coordinates from the matrix multiplication to generate the IS.

\section{Implementation of this methodology}

The code that implements this methodology is explained in Appendix \ref{ch:code}.